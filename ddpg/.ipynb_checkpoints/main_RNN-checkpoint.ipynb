{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib as tc\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from replay_buffer import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(object):\n",
    "    def __init__(self, sess, nObs, nAct, actionBound, lr, tau, \\\n",
    "                 nodes, batchSize, trainable, layer_norm):\n",
    "        self.sess = sess\n",
    "        self.nObs = nObs\n",
    "        self.nAct = nAct\n",
    "        self.actionBound = actionBound\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        self.nodes = nodes\n",
    "        self.batchSize = batchSize\n",
    "        self.trainable = trainable\n",
    "        self.layer_norm = layer_norm\n",
    "        \n",
    "        with tf.variable_scope('actor'):\n",
    "            self.obs, self.action, self.scaledAction = self.buildNet()\n",
    "            \n",
    "        self.netParams = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'actor')\n",
    "        \n",
    "        with tf.variable_scope('target_actor'):\n",
    "            self.target_obs, self.target_action, self.target_scaledAction = self.buildNet()\n",
    "        \n",
    "        self.target_netParams = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'target_actor')\n",
    "        self.update_target = \\\n",
    "            [self.target_netParams[i].assign(tf.multiply(self.netParams[i], self.tau) + \\\n",
    "                                             tf.multiply(self.target_netParams[i], 1. - self.tau))\n",
    "                        for i in range(len(self.target_netParams))]\n",
    "        \n",
    "        # from critic with action taken\n",
    "        self.actionGrads = tf.placeholder(tf.float32, [None, self.nAct], 'gradient')\n",
    "        \n",
    "        # actor gradients\n",
    "        self.grads_ = tf.gradients(self.scaledAction, self.netParams, \\\n",
    "                                 -self.actionGrads)\n",
    "        # normalized actor gradients by batchSize\n",
    "        self.grads = list(map(lambda x: tf.div(x, self.batchSize), \\\n",
    "                             self.grads_))\n",
    "        \n",
    "        self.optimize = tf.train.AdamOptimizer(self.lr).apply_gradients(\\\n",
    "                        zip(self.grads, self.netParams))\n",
    "        \n",
    "    def buildNet(self):\n",
    "        obs = tf.placeholder(tf.float32, [None, self.nObs], 'observation')\n",
    "\n",
    "        \n",
    "        W1 = tf.get_variable(\"W1\", [self.nObs, self.nodes[0]],\n",
    "                       initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b1 = tf.Variable(tf.random_normal([self.nodes[0]]))\n",
    "        if self.layer_norm:\n",
    "            L1_norm = tc.layers.layer_norm(tf.add(tf.matmul(obs, W1), b1), \\\n",
    "                                          center=True, scale=True)\n",
    "            L1 = tf.nn.relu(L1_norm)\n",
    "        else:\n",
    "            L1 = tf.nn.relu(tf.add(tf.matmul(obs, W1), b1))\n",
    "\n",
    "        W2 = tf.get_variable(\"W2\", [self.nodes[0], self.nodes[1]],\n",
    "                       initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2 = tf.Variable(tf.random_normal([self.nodes[1]]))\n",
    "        if self.layer_norm:\n",
    "            L2_norm = tc.layers.layer_norm(tf.add(tf.matmul(L1, W2), b2), \\\n",
    "                                      center=True, scale=True)\n",
    "            L2 = tf.nn.relu(L2_norm)\n",
    "        else:\n",
    "            L2 = tf.nn.relu(tf.add(tf.matmul(L1, W2), b2))\n",
    "\n",
    "\n",
    "        \n",
    "        W3 = tf.get_variable(\"W3\", [self.nodes[1], self.nAct],\n",
    "                       initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b3 = tf.Variable(tf.random_normal([self.nAct]))\n",
    "\n",
    "        action = tf.nn.tanh(tf.add(tf.matmul(L2, W3), b3))    \n",
    "        scaledAction = tf.multiply(action, self.actionBound)\n",
    "    \n",
    "        return obs, action, scaledAction\n",
    "   \n",
    "    def gen_action(self, s):\n",
    "        return self.sess.run(self.scaledAction, {self.obs: s})\n",
    "        \n",
    "    def target_gen_action(self, s):\n",
    "        return self.sess.run(self.target_scaledAction, {self.target_obs: s})\n",
    "        \n",
    "    def train(self, s, grads):\n",
    "        self.sess.run(self.optimize, {self.obs: s, self.actionGrads: grads})\n",
    "        \n",
    "    def update_target_net(self):\n",
    "        self.sess.run(self.update_target)\n",
    "    \n",
    "    def get_num_net_params(self):\n",
    "        return len(self.netParams) + len(self.target_netParams)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(object):\n",
    "    def __init__(self, sess, nObs, nAct, lr, tau, gamma, nodes,\\\n",
    "                 trainable, layer_norm):\n",
    "        self.sess = sess\n",
    "        self.nObs = nObs\n",
    "        self.nAct = nAct\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "        self.nodes = nodes\n",
    "        self.trainable = trainable \n",
    "        self.layer_norm = layer_norm\n",
    "        \n",
    "        with tf.variable_scope('critic'):\n",
    "            self.obs, self.action, self.v = self.buildNet()\n",
    "            \n",
    "        self.netParams = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='critic')\n",
    "    \n",
    "        with tf.variable_scope('target_critic'):\n",
    "            self.target_obs, self.target_action, self.target_v = self.buildNet()\n",
    "        \n",
    "        self.target_netParams = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target_critic')\n",
    "    \n",
    "        self.update_target = \\\n",
    "            [self.target_netParams[i].assign(tf.multiply(self.netParams[i], self.tau) + \\\n",
    "                                             tf.multiply(self.target_netParams[i], 1. - self.tau))\n",
    "                        for i in range(len(self.target_netParams))]\n",
    "        \n",
    "        self.actionGrads = tf.gradients(self.v, self.action)\n",
    "        \n",
    "        # from target\n",
    "        self.predictedQ = tf.placeholder(tf.float32, [None, 1])\n",
    "        \n",
    "        self.loss = tf.reduce_sum(tf.square(self.predictedQ - self.v))\n",
    "        self.optimize = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "                \n",
    "        \n",
    "    def buildNet(self):\n",
    "        obs = tf.placeholder(tf.float32, [None, self.nObs], 'observation')\n",
    "        a = tf.placeholder(tf.float32, [None, self.nAct], 'action')\n",
    "                         \n",
    "        W1 = tf.get_variable(\"W1\", [self.nObs, self.nodes[0]], \\\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b1 = tf.Variable(tf.random_normal([self.nodes[0]]), 'b1')\n",
    "        cell = tf.nn.rnn_cell.BasicRNNCell(self.nodes[0])\n",
    "        \n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, obs, dtype=tf.float32)\n",
    "        \n",
    "        outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "        outputs = outputs[-1]\n",
    "        \n",
    "        if self.layer_norm:\n",
    "            L1_norm = tc.layers.layer_norm(tf.add(tf.matmul(outputs, W1), b1), \\\n",
    "                                      center=True, scale=True)\n",
    "            L1 = tf.nn.relu(L1_norm)\n",
    "        else:\n",
    "            L1 = tf.nn.relu(tf.add(tf.matmul(outputs, w1), b1))\n",
    "        \n",
    "        W2 = tf.get_variable('W2', [self.nodes[0], self.nodes[1]], \\\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2 = tf.Variable(tf.random_normal([self.nodes[1]]))\n",
    "       \n",
    "        W2_ = tf.get_variable('W2_', [self.nAct, self.nodes[1]], \\\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2_ = tf.Variable(tf.random_normal([self.nodes[1]]))\n",
    "        if self.layer_norm:\n",
    "            L2_norm = tc.layers.layer_norm(\n",
    "                tf.matmul(L1, W2) + b2 + tf.matmul(a, W2_) + b2_, \\\n",
    "                                      center=True, scale=True)\n",
    "            L2 = tf.nn.relu(L2_norm)\n",
    "        else:\n",
    "            L2 = tf.nn.relu(\n",
    "                tf.matmul(L1, W2) + b2 + tf.matmul(a, W2_) + b2_)\n",
    "\n",
    "        \n",
    "        W3 = tf.get_variable('W3', [self.nodes[1], 1], \\\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b3 = tf.Variable(tf.random_normal([1]))\n",
    "        v = tf.matmul(L2, W3) + b3\n",
    "\n",
    "        return obs, a, v\n",
    "    \n",
    "    def gen_value(self, s, a):\n",
    "        return self.sess.run(self.v, {self.obs: s, self.action: a})\n",
    "        \n",
    "    def target_gen_value(self, s, a):\n",
    "        return self.sess.run(self.target_v, {self.target_obs: s, \n",
    "                                             self.target_action: a})\n",
    "        \n",
    "    def train(self, s, a, q):\n",
    "        return self.sess.run([self.v, self.optimize], \\\n",
    "                                  {self.obs: s, self.action: a,\\\n",
    "                                      self.predictedQ: q})\n",
    "        \n",
    "    def get_action_grads(self, s, a):\n",
    "        return self.sess.run(self.actionGrads, {self.obs: s, self.action: a})\n",
    "        \n",
    "    def update_target_net(self):\n",
    "        self.sess.run(self.update_target)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrnsteinUhlenbeckActionNoise:\n",
    "    def __init__(self, mu, sigma=0.3, theta=.15, dt=1e-2, x0=None):\n",
    "        self.theta = theta\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.dt = dt\n",
    "        self.x0 = x0\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "                self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(self.mu, self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, stats):\n",
    "    if stats is None:\n",
    "        return x\n",
    "    \n",
    "    return (x - stats.mean)/stats.std\n",
    "\n",
    "def denormalize(x, stats):\n",
    "    if stats is None:\n",
    "        return x\n",
    "    \n",
    "    return x*stats.std + stats.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_summaries():\n",
    "    ep_reward = tf.Variable(0.)\n",
    "    tf.summary.scalar(\"Reward\", ep_reward)\n",
    "    ep_Qmax = tf.Variable(0.)\n",
    "    tf.summary.scalar(\"Qmax\", ep_Qmax)\n",
    "\n",
    "    summary_vars = [ep_reward, ep_Qmax]\n",
    "    summary_ops = tf.summary.merge_all()\n",
    "\n",
    "    return summary_ops, summary_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Pendulum-v0 ************\n",
      "  observation: 3   |   action: 1\n",
      "************************************\n"
     ]
    }
   ],
   "source": [
    "random_seed = '1234'\n",
    "envName = 'Pendulum-v0'\n",
    "env = gym.make(envName)\n",
    "\n",
    "nObs = env.observation_space.shape[0]\n",
    "nAct = env.action_space.shape[0]\n",
    "actionBound = env.action_space.high\n",
    "print(\"*********** {} ************\".format(envName))\n",
    "print('  observation: {}   |   action: {}'.format(nObs, nAct))\n",
    "print(\"************************************\")\n",
    "\n",
    "\n",
    "actorLr = 1e-3\n",
    "actorNodes = [16, 64]\n",
    "criticNodes = [16, 64]\n",
    "criticLr = 1e-2\n",
    "tau = 1e-3\n",
    "batchSize = 64\n",
    "gamma = 0.99\n",
    "bufferSize = 1e6\n",
    "layer_norm = True\n",
    "\n",
    "episode = 200\n",
    "step = 200\n",
    "render = False\n",
    "\n",
    "summaryFile = './log/summary_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape (3, ?) must have rank at least 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-536617247f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m critic = Critic(sess, nObs=nObs, nAct=nAct, lr=criticLr, tau=tau, nodes=criticNodes, \\\n\u001b[0;32m---> 11\u001b[0;31m             gamma=gamma, trainable=True, layer_norm=layer_norm)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mactorNoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrnsteinUhlenbeckActionNoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnAct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-581bb184c566>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess, nObs, nAct, lr, tau, gamma, nodes, trainable, layer_norm)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'critic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAINABLE_VARIABLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'critic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-581bb184c566>\u001b[0m in \u001b[0;36mbuildNet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasicRNNCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/p3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/p3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m   inputs_got_shape = tuple(input_.get_shape().with_rank_at_least(3)\n\u001b[0;32m--> 727\u001b[0;31m                            for input_ in flat_input)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   \u001b[0mconst_time_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconst_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_got_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/p3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m   inputs_got_shape = tuple(input_.get_shape().with_rank_at_least(3)\n\u001b[0;32m--> 727\u001b[0;31m                            for input_ in flat_input)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   \u001b[0mconst_time_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconst_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_got_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/p3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank_at_least\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \"\"\"\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank at least %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape (3, ?) must have rank at least 3"
     ]
    }
   ],
   "source": [
    "summary_ops, summary_vars = build_summaries()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session(config=config)\n",
    "writer = tf.summary.FileWriter(summaryFile, sess.graph)\n",
    "\n",
    "actor = Actor(sess, nObs=nObs, nAct=nAct, lr=actorLr, tau=tau, nodes=actorNodes, \\\n",
    "    batchSize=batchSize, actionBound=actionBound, trainable=True, layer_norm=layer_norm)\n",
    "\n",
    "critic = Critic(sess, nObs=nObs, nAct=nAct, lr=criticLr, tau=tau, nodes=criticNodes, \\\n",
    "            gamma=gamma, trainable=True, layer_norm=layer_norm)\n",
    "\n",
    "actorNoise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(nAct))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "actor.update_target_net()\n",
    "critic.update_target_net()\n",
    "\n",
    "replayBuffer = ReplayBuffer(bufferSize)\n",
    "\n",
    "R, Qmax = [], []\n",
    "\n",
    "for nEp in range(episode):\n",
    "    s = env.reset()\n",
    "    \n",
    "    ep_reward = 0\n",
    "    ep_Qmax = 0\n",
    "    for nStep in range(step):\n",
    "        a = actor.gen_action(np.reshape(s, (1, actor.nObs))) + actorNoise()\n",
    "        \n",
    "        s2 , r, done, info = env.step(a[0])\n",
    "            \n",
    "        replayBuffer.add(np.reshape(s, (actor.nObs,)), np.reshape(a, (actor.nAct,)),\\\n",
    "                         r, done, np.reshape(s2, (actor.nObs, )))\n",
    "        \n",
    "        if replayBuffer.size() > batchSize:\n",
    "            sBatch, aBatch, rBatch, doneBatch, s2Batch = \\\n",
    "                            replayBuffer.sample_batch(batchSize)\n",
    "            \n",
    "            targetQ = critic.target_gen_value(s2Batch, \\\n",
    "                        actor.gen_action(s2Batch))\n",
    "            \n",
    "            for i in range(batchSize):\n",
    "                if not doneBatch[i]:\n",
    "                    rBatch[i] = rBatch[i] + critic.gamma*targetQ[i]\n",
    "                    \n",
    "            predictedQ, _ = critic.train(sBatch, aBatch, np.reshape(rBatch, (batchSize, 1)))\n",
    "            \n",
    "            ep_Qmax += np.amax(predictedQ)\n",
    "            \n",
    "            grads = critic.get_action_grads(sBatch, actor.gen_action(sBatch))\n",
    "            actor.train(sBatch, grads[0])\n",
    "            \n",
    "            actor.update_target_net()\n",
    "            critic.update_target_net()\n",
    "            \n",
    "        s = s2\n",
    "        ep_reward += r\n",
    "        \n",
    "        print('\\rReward: {:d} | Episode: {:d} | Qmax: {:.4f}'.format(int(ep_reward), \\\n",
    "                    nEp, (ep_Qmax / (float(nStep)+0.1))), end='')\n",
    "            \n",
    "    if done:\n",
    "        print('\\n')\n",
    "        Qmax.append(ep_Qmax / (float(nStep)+0.1))\n",
    "        R.append(ep_reward)\n",
    "        \n",
    "#         summary_str = sess.run(summary_ops, feed_dict=\\\n",
    "#                               {summary_vars[0]: 1,\n",
    "#                                summary_vars[1]: 1})\n",
    "#         writer.add_summary(summary_str, nEp)\n",
    "#         writer.flush()\n",
    "        \n",
    "        if nEp != 0 and nEp % 20 == 0:\n",
    "            fig = plt.figure(figsize=(20, 10))\n",
    "            plt.style.use('seaborn-darkgrid')\n",
    "            plt.subplot(211)\n",
    "            plt.plot(range(len(R)), R)\n",
    "            plt.title(\"reward per episode\")\n",
    "            plt.subplot(212)\n",
    "            plt.plot(range(len(Qmax)), Qmax)\n",
    "            plt.title(\"Qmax per episode\")\n",
    "            plt.savefig(\"./figs/results/results_\" + str(nEp) + \".png\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues when building actor & critic net.\n",
    "\n",
    "* <U>**Assigning weight and bias variables is better as the above than the below**</U>\n",
    "\n",
    "x = tf.layers.dense(obs, units=self.nodes[0], activation=tf.nn.relu,    trainable=self.trainable, name='p_fc0') \n",
    "                         \n",
    "x = tf.layers.dense(x, units=self.nodes[1], activation=tf.nn.relu, trainable=self.trainable, name='p_fc1')     \n",
    "                         \n",
    "action = tf.layers.dense(x, units=self.nAct, activation=tf.nn.relu,\n",
    "trainable=self.trainable, name='p_fc2')\n",
    "                         \n",
    "scaledAction = tf.multiply(action, self.actionBound)\n",
    "\n",
    "-------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "* <U>**The below \"batch normalization\" does not work well**</U> \n",
    "\n",
    "L1 = tf.nn.relu(tf.contrib.layers.batch_norm(tf.add(tf.matmul(obs, W1), b1)))\n",
    "\n",
    "L2 = tf.nn.relu(tf.contrib.layers.batch_norm(tf.add(tf.matmul(L1, W2), b2)))\n",
    "\n",
    "-------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "* <U>**Getting trainable variables of networks:**</U>\n",
    "\n",
    "self.netParams = tf.trainable_variables()\n",
    "\n",
    "self.target_netParams = tf.trainable_variables()[len(self.netParams):]\n",
    "        \n",
    "self.netParams = tf.trainable_variables()[numActorParams:]\n",
    "\n",
    "self.target_netParams = tf.trainable_variables()[len(self.netParams) + numActorParams:]\n",
    "\n",
    "> **The above method is not good, b/c it requires the number of trainable variables in each networks(actor, target_actor, critic, target_critic). Thus, the below method is better !!! \n",
    "In this way, it just requires the scope of each network to classify.**\n",
    "\n",
    "self.netParams = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'actor')\n",
    "\n",
    "self.target_netParams = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope = 'target_actor')\n",
    "\n",
    "self.netParams = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='critic')\n",
    "  \n",
    "self.target_netParams = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target_critic')\n",
    "  \n",
    "\n",
    "-------------------------------------------------------------------------\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
